import matplotlib
matplotlib.use('TkAgg')
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim


# 读取 Excel 文件
data = pd.read_excel('new.xlsx', engine='openpyxl')
data['Date'] = pd.to_datetime(data['Date'])
data = data.set_index('Date')
print(data)
# 提取目标列并归一化
scaler = MinMaxScaler(feature_range=(0, 1))
data_normalized = scaler.fit_transform(data[['Number of  reported results']].values)
data_tensor = torch.FloatTensor(data_normalized).view(-1)

# 创建数据集
def create_dataset(dataset, look_back):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back):
        a = dataset[i:(i+look_back)]
        dataX.append(a)
        dataY.append(dataset[i + look_back])
    return torch.stack(dataX), torch.stack(dataY)

# 定义 GRU 模型
class GRUModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(GRUModel, self).__init__()
        self.hidden_size = hidden_size
        self.gru = nn.GRU(input_size, hidden_size,num_layers=1, batch_first=True)
        self.linear = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.1)

    def forward(self, x):
        out, _ = self.gru(x)
        out = self.linear(out[:, -1, :])
        return out

look_back = 5
# 数据集划分
train_size = int(len(data_tensor) * 0.7)
test_size = len(data_tensor) - train_size

train_data, test_data = data_tensor[0:train_size], data_tensor[train_size:len(data_tensor)]
trainX, trainY = create_dataset(train_data, look_back)
testX, testY = create_dataset(test_data, look_back)

trainX = trainX.view(-1, 1, look_back)
trainY = trainY.view(-1, 1)
testX = testX.view(-1, 1, look_back)
testY = testY.view(-1, 1)

look_back = 5
input_size = look_back  # 确保定义了input_size
hidden_size = 32
output_size = 1
num_epochs = 2000  # 您可以根据需要调整此值
# 为3月1日的预测建立一个空列表
march_1st_predictions = []

# 运行模型100次
for iteration in range(1000):
    # 初始化模型、损失函数和优化器
    model = GRUModel(input_size, hidden_size, output_size)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 训练模型
    for epoch in range(num_epochs):
        outputs = model(trainX)
        optimizer.zero_grad()
        loss = criterion(outputs, trainY)
        loss.backward()
        optimizer.step()

    # 进行预测并存储预测结果
    predictions = []
    future_data = data_tensor[-look_back:].view(1, 1, look_back)
    for i in range(60):  # 假设3月1日是未来第60天
        prediction = model(future_data)
        future_data = torch.cat([future_data[:, :, 1:], prediction.view(1, 1, 1)], dim=2)
        predictions.append(prediction.view(-1).item())

    # 将预测结果逆归一化
    predicted_values = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))

    # 获取并打印3月1日的预测结果
    march_1st_prediction = predicted_values[59][0]  # 获取3月1日的预测结果
    print(f"第{iteration+1}轮预测，3月1日的预测值: {march_1st_prediction}")

    # 将结果添加到列表中
    march_1st_predictions.append(march_1st_prediction)

# 计算3月1日预测的平均值和标准差
mean_prediction = np.mean(march_1st_predictions)
std_deviation = np.std(march_1st_predictions)

# 打印平均预测结果和标准差
print(f"\n3月1日的平均预测值: {mean_prediction}")
print(f"3月1日的预测标准差: {std_deviation}")
