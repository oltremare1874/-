import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

df = pd.read_excel('try.xlsx', engine='openpyxl')
# 划分自变量和目标变量
X = df[['x', 'x2']].values
y = df[['x3', 'value']].values
print(X)
# 将数据集拆分为70%训练样本数据，30%为测试样本数据
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,test_size=0.3, random_state=42)

# 设置随机森林回归模型的参数
param_grid = {
    'n_estimators': [10, 50, 100, 200, 400],
    'max_depth': [None, 10, 20, 30, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['log2', 'sqrt']
}

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# 网格搜索法确定最佳参数
rf = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs = -1)
grid_search.fit(X_train, y_train)

# 输出最佳参数
print(grid_search.best_params_)


# 输出最佳模型的MSE和R^2
best_rf = grid_search.best_estimator_
test_predictions = best_rf.predict(X_test)
best_mse = mean_squared_error(y_test, test_predictions)
best_r2 = r2_score(y_test, test_predictions)
print('MSE of the best model: ', best_mse)
print('R^2 of the best model: ', best_r2)

x = [[1, 1]]
prediction = best_rf.predict(x)
print(prediction)


# 假设我们添加均值为0，标准差为0.5的高斯噪声
std_dev = 0.5
gaussian_noise = np.random.normal(0, std_dev, X_test.shape)

# 添加噪声到测试集
X_test_noisy = X_test + gaussian_noise

# 使用带有噪声的测试集进行预测
test_predictions_noisy = best_rf.predict(X_test_noisy)

# 计算带噪声的测试集的MSE和R²
mse_noisy = mean_squared_error(y_test, test_predictions_noisy)
r2_noisy = r2_score(y_test, test_predictions_noisy)

# 打印结果
print('MSE with noise: ', mse_noisy)
print('R² with noise: ', r2_noisy)
